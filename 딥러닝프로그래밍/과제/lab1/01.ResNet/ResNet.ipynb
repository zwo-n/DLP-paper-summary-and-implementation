{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHO-jaFj9Zm"
      },
      "source": [
        "#LAB 1: VGGNet & ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVdm1LA1j9Zo"
      },
      "source": [
        "<h4><div style=\"text-align: right\"> Due date: 15:00 Oct 02, 2025.  </div> <br>\n",
        "<div style=\"text-align: right\"> Please upload your file and final-report at PLATO before the class in the form of [ID_Name_Lab1.ipynb]. </div></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cl2DqlTj9Zp"
      },
      "source": [
        "### *Instructions:*\n",
        "- Write a program implementing a particular algorithm to solve a given problem.   \n",
        "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span>\n",
        "- You must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKipoMbMj9Zq"
      },
      "source": [
        "<h2><span style=\"color:blue\">[202355514] [강지원]</span> </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL1pbTi2j9Zr",
        "outputId": "54c93ea7-988e-4a7f-8924-27b4283600f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code is written at 2025-09-30 04:03:10.329527\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(\"This code is written at \" + str(datetime.datetime.now()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rfPXXDMkcpZ",
        "outputId": "fd013b7b-e7a1-4d2a-c675-f99c77baa236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version\n",
            "sys.version_info(major=3, minor=12, micro=11, releaselevel='final', serial=0)\n",
            "\n",
            "OS information\n",
            "Linux-6.6.97+-x86_64-with-glibc2.35\n",
            "\n",
            "Is GPU available?\n",
            "True\n",
            "\n",
            "GPU information\n",
            "Tue Sep 30 16:21:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#####################################################################\n",
        "# In order to use GPU acceleration, you must change runtime type.\n",
        "# See the menu bar above.\n",
        "# \"Runtime\" -> \"Change runtime type\"  -> \"Hardware accelerator\"\n",
        "# Change 'None' to 'GPU', then run the code below.\n",
        "#####################################################################\n",
        "\n",
        "import sys\n",
        "import platform\n",
        "import torch\n",
        "\n",
        "print(\"Python version\")\n",
        "print(sys.version_info)\n",
        "\n",
        "print(\"\\nOS information\")\n",
        "print(platform.platform())\n",
        "\n",
        "print(\"\\nIs GPU available?\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# print(\"\\nCPU information\")\n",
        "# !cat /proc/cpuinfo\n",
        "\n",
        "# print(\"\\nMemory information\")\n",
        "# !cat /proc/meminfo\n",
        "\n",
        "print(\"\\nGPU information\")\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpPLjwr8j9Zw"
      },
      "source": [
        "## 1. VGGNet with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWeEYLiSj9Zx"
      },
      "source": [
        "### Implementing VGGNet\n",
        "\n",
        "1. **Dataset**\n",
        " - Images from the first three categories in CIFAR-10. (Due to the computational constraints.)  <br>\n",
        "     Three categories : plane, car, bird  /  The number of training images : 15,000   /  The number of test images : 3,000\n",
        " - Augmented with flipping and random cropping.\n",
        "\n",
        " 2. **Network architecture**\n",
        " - Type-D configuration in the paper (+ 3-way classifier after convolutional layers).\n",
        " - ReLU activation.\n",
        " - No dropout for simplicity.\n",
        " - We will apply **batch-normalization** after every convolution which is not used in the paper (otherwise, hard to optimize).\n",
        "\n",
        " <table><tr>\n",
        " <td> <img src=\"https://docs.google.com/uc?export=download&id=1WoLTNYR11nbIE7ovpaum2DN_u71zow6r\" alt=\"no_image\" style=\"width: 550px;\"/> </td>\n",
        " </tr></table>\n",
        "\n",
        " <font size=\"0.5\"> Figure from <br>\n",
        " [1] https://www.quora.com/What-is-the-VGG-neural-network </font>\n",
        "\n",
        "3. **Loss function**\n",
        " - Cross-entropy loss between outputs & ground-truths. <br>\n",
        "     Note that `nn.CrossEntroyLoss` takes logits before softmax as network outputs and scalar index (not one-hot vector) as ground-truths.<br>\n",
        "     See https://pytorch.org/docs/stable/nn.html#crossentropyloss for details.\n",
        "\n",
        " 4. **Training**\n",
        " - Default weight initialization for simplicity.\n",
        " - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
        " - 20 epochs without learning rate scheduling.\n",
        "\n",
        " 5. **Evaluation metric**\n",
        " - Classification accuracy (i.e., the percentage of correct predictions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LGgir5u7j9Zy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision\n",
        "import time\n",
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwvpXFuaj9Z0",
        "outputId": "33b8c8b8-6981-4c0d-8fa1-71beddc8527c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: LOADING DATASET\n"
          ]
        }
      ],
      "source": [
        "print('STEP 1: LOADING DATASET')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                            train=True,\n",
        "                            transform=transform_train,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                           train=False,\n",
        "                           transform=transform_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DrK0ZHmLj9Z4"
      },
      "outputs": [],
      "source": [
        "# reducing the dataset\n",
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_test_dataset.append((images, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWnYJ2cwj9Z6",
        "outputId": "f6580bb1-38bc-40df-a0c2-e5ed51ebd525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training images :  15000\n",
            "The number of test images :  3000\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of training images : \", len(reduced_train_dataset))\n",
        "print(\"The number of test images : \", len(reduced_test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFq0isyCj9Z-",
        "outputId": "7d390f60-e1cb-412f-ac99-e387b3970b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE\n"
          ]
        }
      ],
      "source": [
        "print('STEP 2: MAKING DATASET ITERABLE')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy7GW1lkj9aB"
      },
      "source": [
        "### Visualize a few images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tJGv35Alj9aC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3PYou4Cuj9aE"
      },
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
        "    std = np.array([0.2023, 0.1994, 0.2010])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "jX59AE2pj9aH",
        "outputId": "fa7b22b5-056b-4118-9092-af11326ed0ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_loader_sample = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loader_sample))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzbc_fTrj9aM"
      },
      "source": [
        "### 1.1 Write code (VGG 16) [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjeNHb89j9aN",
        "outputId": "85ee42c1-0265-4dff-f902-19437e3555ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 3: CREATE MODEL CLASS (VGG16)\n"
          ]
        }
      ],
      "source": [
        "print('STEP 3: CREATE MODEL CLASS (VGG16)')\n",
        "\n",
        "#############\n",
        "# CODE HERE #\n",
        "#############\n",
        "\n",
        "## BatchNorm2d(in_channel)\n",
        "\n",
        "cfg = [64, 64, 'MP', 128, 128, 128, 'MP', 512, 512, 512, 'MP', 512, 512, 512, 'MP']\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "        self.VGG16 = self._make_layers(cfg)\n",
        "        self.classifier = nn.Linear(512*2*2, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.VGG16(x)\n",
        "        # print(\"Shape before flattening:\", out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        # print(\"Shape after flattening:\", out.shape)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self,cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'MP':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.ReLU(inplace=True),\n",
        "                           nn.BatchNorm2d(x)]\n",
        "                in_channels = x\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "iqoPZuR3j9aQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6523c52-a63f-4376-fcc9-b47872e7c5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 4: INSTANTIATE MODEL CLASS\n",
            "The number of parameters :  12810435\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (VGG16): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): ReLU(inplace=True)\n",
              "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): ReLU(inplace=True)\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2048, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
        "\n",
        "model = VGG()\n",
        "num_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"The number of parameters : \", num_total_params)\n",
        "\\\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFeamtXXj9aT",
        "outputId": "cbd9f166-be23-45ea-8e24-01fd3dd7fab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS\n"
          ]
        }
      ],
      "source": [
        "print('STEP 5: INSTANTIATE LOSS CLASS')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n",
        "\n",
        "learning_rate = 1e-2\n",
        "momentum = 0.9\n",
        "weight_decay = 5e-4\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum, weight_decay = weight_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaWErvoRj9aY"
      },
      "source": [
        "### 1.2 Train the VGG 16 model and print test accuracy for every epochs [2 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbi85f2Pj9aY",
        "outputId": "ce4e3ec9-1384-48db-ba71-b50e293287ce",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 7: TRAIN THE MODEL\n",
            "Epochs: 0. Loss: 1.3608666693760176. Accuracy: 60.14666666666667. Elapsed time: 7.862557888031006 sec\n",
            "Epochs: 1. Loss: 0.702910938505399. Accuracy: 73.94. Elapsed time: 8.066734790802002 sec\n",
            "Epochs: 2. Loss: 0.6125931030107756. Accuracy: 77.45333333333333. Elapsed time: 8.278175830841064 sec\n",
            "Epochs: 3. Loss: 0.44523664576522376. Accuracy: 82.46. Elapsed time: 8.186424016952515 sec\n",
            "Epochs: 4. Loss: 0.4376034847760605. Accuracy: 83.62666666666667. Elapsed time: 7.9537036418914795 sec\n",
            "Epochs: 5. Loss: 0.37528093967397336. Accuracy: 85.15333333333334. Elapsed time: 7.824023246765137 sec\n",
            "Epochs: 6. Loss: 0.32727092365592214. Accuracy: 87.38. Elapsed time: 7.769190788269043 sec\n",
            "Epochs: 7. Loss: 0.30299321246349203. Accuracy: 88.20666666666666. Elapsed time: 7.74968147277832 sec\n",
            "Epochs: 8. Loss: 0.2507429179751267. Accuracy: 90.22. Elapsed time: 7.73651385307312 sec\n",
            "Epochs: 9. Loss: 0.6231601821669077. Accuracy: 79.49333333333334. Elapsed time: 7.7528088092803955 sec\n",
            "Epochs: 10. Loss: 0.3486203084052619. Accuracy: 86.42666666666666. Elapsed time: 7.8187010288238525 sec\n",
            "Epochs: 11. Loss: 0.2823869497594187. Accuracy: 89.26666666666667. Elapsed time: 7.877025842666626 sec\n",
            "Epochs: 12. Loss: 0.22986125857648204. Accuracy: 91.20666666666666. Elapsed time: 7.938992977142334 sec\n",
            "Epochs: 13. Loss: 0.24868378655637724. Accuracy: 90.64666666666666. Elapsed time: 7.951797723770142 sec\n",
            "Epochs: 14. Loss: 0.18145811646166493. Accuracy: 93.24. Elapsed time: 7.93253231048584 sec\n",
            "Epochs: 15. Loss: 0.1523963273581812. Accuracy: 94.14666666666666. Elapsed time: 7.905953407287598 sec\n",
            "Epochs: 16. Loss: 0.14257291530779861. Accuracy: 94.63333333333334. Elapsed time: 7.858804941177368 sec\n",
            "Epochs: 17. Loss: 0.10902313752320864. Accuracy: 95.79333333333334. Elapsed time: 7.840571165084839 sec\n",
            "Epochs: 18. Loss: 0.0899287797510624. Accuracy: 96.58. Elapsed time: 7.825768709182739 sec\n",
            "Epochs: 19. Loss: 0.07777975027654636. Accuracy: 97.08666666666666. Elapsed time: 7.817760705947876 sec\n"
          ]
        }
      ],
      "source": [
        "print('STEP 7: TRAIN THE MODEL')\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = (correct / total) * 100\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb-Zo5yOj9ac"
      },
      "source": [
        "## 2. ResNet with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQeESvzij9ad"
      },
      "source": [
        "### Implementing ResNet\n",
        "\n",
        " 1. **Dataset**\n",
        " - The same dataset used for VGGNet\n",
        "\n",
        " 2. **Network architecture**\n",
        " - 50-layer ResNet with **bottleneck blocks**. <br>\n",
        "     Note. The initial convolution layer (i.e., conv1) is different from the one in the paper &<br>\n",
        "     the initial max-pooling layer is removed (because the size of CIFAR-10 images is too small).\n",
        " - ReLU activation.\n",
        " - Strided convolution for down-sampling instead of max-pooling layer. <br>\n",
        "     Note. Once down-sampled, a $1\\times1$ convolution/stride 2 is applied to residual for expanding the channel of the residual.\n",
        " - No dropout for simplicity.\n",
        " - Batch-normalization after every convolution.\n",
        "\n",
        "\n",
        " <table><tr>\n",
        " <td> <img src=\"https://docs.google.com/uc?export=download&id=1UbSh2w83Tb0VVgXxyly_VAUPwE7UsdAE\" alt=\"no_image\" style=\"width: 500px;\"/> </td>\n",
        " </tr></table>\n",
        "\n",
        " <font size=\"0.5\"> Figures from <br>\n",
        " [1] https://www.codeproject.com/Articles/1248963/Deep-Learning-using-Python-plus-Keras-Chapter-Re  <br>\n",
        " [2] Rezende et al., *Signal Processing: Image Communication*, 2018. </font>\n",
        "\n",
        "3. **Loss function**\n",
        "- Cross-entropy loss between outputs & ground-truths. <br>\n",
        "\n",
        "4. **Training**\n",
        " - Default weight initialization for simplicity.\n",
        " - SGD optimizer with `learning rate = 1e-2`, `momentum = 0.9`, and `weight_decay = 5e-4`.\n",
        "- 15 epochs without learning rate scheduling.\n",
        "\n",
        "5. **Evaluation metric**\n",
        " - Classification accuracy (i.e., the percentage of correct predictions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-guPbqGj9ae"
      },
      "source": [
        "### 2.1 Implement ResNet50 and train it with the CIFAR 10 dataset [4 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "21UwX-8Kj9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068155ea-564b-4771-96e4-32f82d8621e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 3: CREATE MODEL CLASS (ResNet-50)\n",
            "STEP 4: INSTANTIATE MODEL CLASS\n"
          ]
        }
      ],
      "source": [
        "print('STEP 3: CREATE MODEL CLASS (ResNet-50)')\n",
        "\n",
        "cfg = [3,4,6,3]\n",
        "\n",
        "class ResNet_block(nn.Module):\n",
        "    def __init__(self, in_c, intra_c, out_c, down_sample = False):\n",
        "        super(ResNet_block, self).__init__()\n",
        "\n",
        "        self.down_sample = down_sample\n",
        "        self.expand = in_c != out_c\n",
        "\n",
        "        stride = 2 if down_sample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, intra_c, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(intra_c, intra_c, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(intra_c, out_c, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        if down_sample or self.expand:\n",
        "            self.convert_id = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_c)\n",
        "            )\n",
        "        else:\n",
        "            self.convert_id = nn.Sequential()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        if self.down_sample or self.expand:\n",
        "            identity = self.convert_id(x)\n",
        "\n",
        "        out = F.relu(out + identity)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.init_block = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.ResBlock1 = self._make_layers(64, 64, 256, cfg[0], down_sample=False)\n",
        "        self.ResBlock2 = self._make_layers(256, 128, 512, cfg[1], down_sample=True)\n",
        "        self.ResBlock3 = self._make_layers(512, 256, 1024, cfg[2], down_sample=True)\n",
        "        self.ResBlock4 = self._make_layers(1024, 512, 2048, cfg[3], down_sample=True)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.classifier = nn.Linear(2048, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.init_block(x)\n",
        "        out = self.ResBlock1(out)\n",
        "        out = self.ResBlock2(out)\n",
        "        out = self.ResBlock3(out)\n",
        "        out = self.ResBlock4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out= out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, in_c, intra_c, out_c, num_block, down_sample):\n",
        "        layers = []\n",
        "        layers.append(ResNet_block(in_c = in_c, intra_c = intra_c, out_c = out_c, down_sample = down_sample))\n",
        "\n",
        "        for _ in range(num_block - 1):\n",
        "            layers.append(ResNet_block(in_c = out_c, intra_c = intra_c, out_c = out_c, down_sample = False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "print('STEP 4: INSTANTIATE MODEL CLASS')\n",
        "\n",
        "model = ResNet()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTFU8J5Uj9aj"
      },
      "source": [
        "### 2.2 Print test accuracy for every epochs. [1 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydsAXR-qj9ak",
        "outputId": "c6038446-30d5-40ad-a65c-a36232ba74e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
            "STEP 7: TRAIN THE MODEL\n",
            "Epochs: 0. Loss: 1.2809745144035856. Accuracy: 54.4. Elapsed time: 48.57177734375 sec\n",
            "Epochs: 1. Loss: 0.6931785802214833. Accuracy: 74.06. Elapsed time: 46.903950691223145 sec\n",
            "Epochs: 2. Loss: 0.5213532271021504. Accuracy: 79.58. Elapsed time: 48.0087194442749 sec\n",
            "Epochs: 3. Loss: 0.46245582603802116. Accuracy: 82.41333333333333. Elapsed time: 47.48534274101257 sec\n",
            "Epochs: 4. Loss: 0.39024251989893993. Accuracy: 85.05333333333333. Elapsed time: 47.692107915878296 sec\n",
            "Epochs: 5. Loss: 0.3818307460869773. Accuracy: 85.64666666666666. Elapsed time: 47.588213205337524 sec\n",
            "Epochs: 6. Loss: 0.31684576290643823. Accuracy: 87.76. Elapsed time: 47.80878400802612 sec\n",
            "Epochs: 7. Loss: 0.28739627690638525. Accuracy: 89.14666666666666. Elapsed time: 47.46664333343506 sec\n",
            "Epochs: 8. Loss: 0.2468026712915655. Accuracy: 90.80666666666667. Elapsed time: 47.559022665023804 sec\n",
            "Epochs: 9. Loss: 0.2018347204489223. Accuracy: 92.35333333333334. Elapsed time: 47.757248640060425 sec\n",
            "Epochs: 10. Loss: 0.18077172275822043. Accuracy: 93.22666666666667. Elapsed time: 47.79693651199341 sec\n",
            "Epochs: 11. Loss: 0.1451643564564697. Accuracy: 94.85333333333334. Elapsed time: 47.692644357681274 sec\n",
            "Epochs: 12. Loss: 0.18438007709396592. Accuracy: 93.27333333333333. Elapsed time: 47.60789704322815 sec\n",
            "Epochs: 13. Loss: 0.09287065592736511. Accuracy: 96.6. Elapsed time: 47.57489323616028 sec\n",
            "Epochs: 14. Loss: 0.08509741242091029. Accuracy: 96.84666666666666. Elapsed time: 47.597341537475586 sec\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Of0nAFXj9an"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion 1-1. RandomCrop만 이용한 경우"
      ],
      "metadata": {
        "id": "d2zTrnmcaOMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STEP 1: LOADING DATASET (RandomCrop Only)')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                            train=True,\n",
        "                            transform=transform_train,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                           train=False,\n",
        "                           transform=transform_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv2TK0TpaUFQ",
        "outputId": "e3a94429-b6a3-43d4-f26b-f67739e74321"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: LOADING DATASET (RandomCrop Only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_test_dataset.append((images, labels))\n",
        "\n",
        "print('STEP 2: MAKING DATASET ITERABLE (RandomCrop Only)')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pqGeeZOayJV",
        "outputId": "3480ef89-336b-4790-8b3d-18d910bd34e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE (RandomCrop Only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS(RandomCrop Only)')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS(RandomCrop Only)')\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL(RandomCrop Only)')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUHTZgZ1a4sc",
        "outputId": "fdd645af-a8c7-43b7-ec9f-fbcdd27dee02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS(RandomCrop Only)\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS(RandomCrop Only)\n",
            "STEP 7: TRAIN THE MODEL(RandomCrop Only)\n",
            "Epochs: 0. Loss: 1.3323032845885068. Accuracy: 54.22. Elapsed time: 44.331655502319336 sec\n",
            "Epochs: 1. Loss: 0.6366709316686049. Accuracy: 75.1. Elapsed time: 46.09127426147461 sec\n",
            "Epochs: 2. Loss: 0.5548643570835308. Accuracy: 78.52. Elapsed time: 46.26763367652893 sec\n",
            "Epochs: 3. Loss: 0.47394128907787597. Accuracy: 81.67333333333333. Elapsed time: 46.24515438079834 sec\n",
            "Epochs: 4. Loss: 0.4130170171038579. Accuracy: 84.28666666666666. Elapsed time: 46.19389033317566 sec\n",
            "Epochs: 5. Loss: 0.4013217783580392. Accuracy: 84.94666666666667. Elapsed time: 46.15779709815979 sec\n",
            "Epochs: 6. Loss: 0.36866771846504537. Accuracy: 86.15333333333334. Elapsed time: 46.33334970474243 sec\n",
            "Epochs: 7. Loss: 0.30746557361493676. Accuracy: 88.42. Elapsed time: 46.42986226081848 sec\n",
            "Epochs: 8. Loss: 0.2553204204571449. Accuracy: 90.45333333333333. Elapsed time: 46.39161491394043 sec\n",
            "Epochs: 9. Loss: 0.22012485532184778. Accuracy: 91.93333333333334. Elapsed time: 46.28680419921875 sec\n",
            "Epochs: 10. Loss: 0.2045791044957557. Accuracy: 92.56. Elapsed time: 46.247820138931274 sec\n",
            "Epochs: 11. Loss: 0.1730989415387986. Accuracy: 93.68666666666667. Elapsed time: 46.23997139930725 sec\n",
            "Epochs: 12. Loss: 0.12659874343771046. Accuracy: 95.52. Elapsed time: 46.226173877716064 sec\n",
            "Epochs: 13. Loss: 0.12395465149844097. Accuracy: 95.55333333333333. Elapsed time: 46.22596263885498 sec\n",
            "Epochs: 14. Loss: 0.09921555798816478. Accuracy: 96.40666666666667. Elapsed time: 46.198692083358765 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion 1-2. RandomHorizontalFlip만 이용한 경우"
      ],
      "metadata": {
        "id": "1rlHqZqegQo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STEP 1: LOADING DATASET (RandomHorizontalFlip Only)')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                            train=True,\n",
        "                            transform=transform_train,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                           train=False,\n",
        "                           transform=transform_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zPrDwGgVZK",
        "outputId": "ec09bd8f-281a-4443-a627-091963019f4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: LOADING DATASET (RandomHorizontalFlip Only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_test_dataset.append((images, labels))\n",
        "\n",
        "print('STEP 2: MAKING DATASET ITERABLE (RandomHorizontalFlip Only)')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wR-gi2RghwG",
        "outputId": "60a96223-ce21-459e-cdc9-b29045a25b69"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE (RandomHorizontalFlip Only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS(RandomHorizontalFlip Only)')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS(RandomHorizontalFlip Only)')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL(RandomHorizontalFlip Only)')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_1shHPvgm41",
        "outputId": "72a0ce91-6a04-48cf-c5bc-fa000dc9fd30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS(RandomHorizontalFlip Only)\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS(RandomHorizontalFlip Only)\n",
            "STEP 7: TRAIN THE MODEL(RandomHorizontalFlip Only)\n",
            "Epochs: 0. Loss: 0.25206999821683107. Accuracy: 90.62666666666667. Elapsed time: 47.70502424240112 sec\n",
            "Epochs: 1. Loss: 0.14560889345356973. Accuracy: 94.66666666666667. Elapsed time: 45.79457712173462 sec\n",
            "Epochs: 2. Loss: 0.09396634872813346. Accuracy: 96.47333333333333. Elapsed time: 46.65084385871887 sec\n",
            "Epochs: 3. Loss: 0.07516197928116988. Accuracy: 97.32. Elapsed time: 46.13857960700989 sec\n",
            "Epochs: 4. Loss: 0.07945164611910359. Accuracy: 97.12. Elapsed time: 46.38106346130371 sec\n",
            "Epochs: 5. Loss: 0.05722977558813863. Accuracy: 97.98666666666666. Elapsed time: 46.34382939338684 sec\n",
            "Epochs: 6. Loss: 0.03558006264285137. Accuracy: 98.65333333333334. Elapsed time: 46.23841452598572 sec\n",
            "Epochs: 7. Loss: 0.03979982632228126. Accuracy: 98.65333333333334. Elapsed time: 46.21467423439026 sec\n",
            "Epochs: 8. Loss: 0.03885036798478183. Accuracy: 98.72. Elapsed time: 46.1899631023407 sec\n",
            "Epochs: 9. Loss: 0.0207716886134684. Accuracy: 99.26. Elapsed time: 46.18083739280701 sec\n",
            "Epochs: 10. Loss: 0.01570522085609609. Accuracy: 99.50666666666666. Elapsed time: 46.28059005737305 sec\n",
            "Epochs: 11. Loss: 0.038123458718596875. Accuracy: 98.62. Elapsed time: 46.236247539520264 sec\n",
            "Epochs: 12. Loss: 0.015056215087050509. Accuracy: 99.46666666666667. Elapsed time: 46.24551701545715 sec\n",
            "Epochs: 13. Loss: 0.013966573819111622. Accuracy: 99.58. Elapsed time: 46.29845857620239 sec\n",
            "Epochs: 14. Loss: 0.016351769491586187. Accuracy: 99.34. Elapsed time: 46.22485852241516 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion 1-3. ColorJitter + RandomHorizontalFlip 이용한 경우"
      ],
      "metadata": {
        "id": "kCbVV-xKilST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "밝기, 대비 및 채도 조정"
      ],
      "metadata": {
        "id": "gPcXTai4j_Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STEP 1: LOADING DATASET (ColorJitter + RandomHorizontalFlip)')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                            train=True,\n",
        "                            transform=transform_train,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                           train=False,\n",
        "                           transform=transform_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKNE-oCNihef",
        "outputId": "cbc85762-0d24-4cf6-ae7a-18366eda20b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: LOADING DATASET (ColorJitter + RandomHorizontalFlip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_test_dataset.append((images, labels))\n",
        "\n",
        "print('STEP 2: MAKING DATASET ITERABLE(ColorJitter + RandomHorizontalFlip)')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWe5DK7ii6n3",
        "outputId": "72531043-fa3e-4dad-de0c-fe5f252b6c6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE(ColorJitter + RandomHorizontalFlip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS(ColorJitter + RandomHorizontalFlip)')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS(ColorJitter + RandomHorizontalFlip)')\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL(ColorJitter + RandomHorizontalFlip)')\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGxxaQunjA0Z",
        "outputId": "b4a5d342-ab90-4569-b5bb-db1180c01106"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS(ColorJitter + RandomHorizontalFlip)\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS(ColorJitter + RandomHorizontalFlip)\n",
            "STEP 7: TRAIN THE MODEL(ColorJitter + RandomHorizontalFlip)\n",
            "Epochs: 0. Loss: 0.18021082136211758. Accuracy: 93.89333333333333. Elapsed time: 47.79988670349121 sec\n",
            "Epochs: 1. Loss: 0.072833415357617. Accuracy: 97.45333333333333. Elapsed time: 45.73178720474243 sec\n",
            "Epochs: 2. Loss: 0.03788480874924463. Accuracy: 98.64666666666666. Elapsed time: 46.71587777137756 sec\n",
            "Epochs: 3. Loss: 0.02570799669503408. Accuracy: 99.22. Elapsed time: 46.16703200340271 sec\n",
            "Epochs: 4. Loss: 0.030652093736581124. Accuracy: 98.88. Elapsed time: 46.403231620788574 sec\n",
            "Epochs: 5. Loss: 0.018900780213929682. Accuracy: 99.32. Elapsed time: 46.4328191280365 sec\n",
            "Epochs: 6. Loss: 0.028759648228237816. Accuracy: 99.06666666666666. Elapsed time: 46.32403755187988 sec\n",
            "Epochs: 7. Loss: 0.018977154248544032. Accuracy: 99.46666666666667. Elapsed time: 46.23326110839844 sec\n",
            "Epochs: 8. Loss: 0.03864213251271995. Accuracy: 98.56666666666666. Elapsed time: 46.225624084472656 sec\n",
            "Epochs: 9. Loss: 0.016285005454230516. Accuracy: 99.56666666666666. Elapsed time: 46.206239461898804 sec\n",
            "Epochs: 10. Loss: 0.04969271074909464. Accuracy: 98.13333333333334. Elapsed time: 46.15345025062561 sec\n",
            "Epochs: 11. Loss: 0.024286502763092264. Accuracy: 99.29333333333334. Elapsed time: 46.185622215270996 sec\n",
            "Epochs: 12. Loss: 0.030913700360481203. Accuracy: 98.89333333333333. Elapsed time: 46.18136525154114 sec\n",
            "Epochs: 13. Loss: 0.008310609212750964. Accuracy: 99.68666666666667. Elapsed time: 46.180803060531616 sec\n",
            "Epochs: 14. Loss: 0.004353005417585136. Accuracy: 99.88. Elapsed time: 46.20246958732605 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion 1-4. GaussianBlur + RandomHorizontalFlip 이용한 경우"
      ],
      "metadata": {
        "id": "00vSLfolkMQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STEP 1: LOADING DATASET (GaussianBlur + RandomHorizontalFlip)')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.GaussianBlur(kernel_size=5),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                            train=True,\n",
        "                            transform=transform_train,\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.CIFAR10(root='./data/CIFAR10/',\n",
        "                           train=False,\n",
        "                           transform=transform_test)\n"
      ],
      "metadata": {
        "id": "7aEPmxnrkLLa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train_dataset = []\n",
        "for images, labels in train_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_train_dataset.append((images, labels))\n",
        "\n",
        "reduced_test_dataset = []\n",
        "for images, labels in test_dataset:\n",
        "    if labels < 3:\n",
        "        reduced_test_dataset.append((images, labels))\n",
        "\n",
        "print('STEP 2: MAKING DATASET ITERABLE(GaussianBlur + RandomHorizontalFlip)')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=reduced_train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=reduced_test_dataset,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)\n",
        "\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD1nzIF-kg0p",
        "outputId": "d0cea320-d071-425b-ecb7-5dbc49074bce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: MAKING DATASET ITERABLE(GaussianBlur + RandomHorizontalFlip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS(GaussianBlur + RandomHorizontalFlip)')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS(GaussianBlur + RandomHorizontalFlip)')\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL(GaussianBlur + RandomHorizontalFlip)')\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ1boz9tk4QK",
        "outputId": "60a98d13-7b3d-4d89-9fe1-953cfcd5a58f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS(GaussianBlur + RandomHorizontalFlip)\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS(GaussianBlur + RandomHorizontalFlip)\n",
            "STEP 7: TRAIN THE MODEL(GaussianBlur + RandomHorizontalFlip)\n",
            "Epochs: 0. Loss: 0.12203259543531526. Accuracy: 96.02. Elapsed time: 47.875810861587524 sec\n",
            "Epochs: 1. Loss: 0.035846100575527395. Accuracy: 98.92. Elapsed time: 45.58474111557007 sec\n",
            "Epochs: 2. Loss: 0.014572060595945282. Accuracy: 99.53333333333333. Elapsed time: 46.75836944580078 sec\n",
            "Epochs: 3. Loss: 0.012765991797851265. Accuracy: 99.54. Elapsed time: 46.179489850997925 sec\n",
            "Epochs: 4. Loss: 0.019652358856608584. Accuracy: 99.39333333333333. Elapsed time: 46.44950318336487 sec\n",
            "Epochs: 5. Loss: 0.03446202120996254. Accuracy: 98.82666666666667. Elapsed time: 46.43768811225891 sec\n",
            "Epochs: 6. Loss: 0.01580032953248612. Accuracy: 99.42666666666666. Elapsed time: 46.39209794998169 sec\n",
            "Epochs: 7. Loss: 0.010525008728648772. Accuracy: 99.67333333333333. Elapsed time: 46.33390021324158 sec\n",
            "Epochs: 8. Loss: 0.03812928600690596. Accuracy: 98.82. Elapsed time: 46.28769540786743 sec\n",
            "Epochs: 9. Loss: 0.024385307238721367. Accuracy: 99.04. Elapsed time: 46.21576428413391 sec\n",
            "Epochs: 10. Loss: 0.017169684558412283. Accuracy: 99.36666666666666. Elapsed time: 46.247478008270264 sec\n",
            "Epochs: 11. Loss: 0.009346331046969173. Accuracy: 99.66. Elapsed time: 46.21380686759949 sec\n",
            "Epochs: 12. Loss: 0.005339000576449029. Accuracy: 99.84. Elapsed time: 46.206172704696655 sec\n",
            "Epochs: 13. Loss: 0.002021611740312468. Accuracy: 99.95333333333333. Elapsed time: 46.23195147514343 sec\n",
            "Epochs: 14. Loss: 0.02765894327949046. Accuracy: 99.1. Elapsed time: 46.18708324432373 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion 2. 마지막 BatchNorm = 0으로 설정한 경우"
      ],
      "metadata": {
        "id": "hqrsi7-ErdVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('STEP 3: CREATE MODEL CLASS (BatchNorm=0)')\n",
        "cfg = [3,4,6,3]\n",
        "\n",
        "class ResNet_block(nn.Module):\n",
        "    def __init__(self, in_c, intra_c, out_c, down_sample = False):\n",
        "        super(ResNet_block, self).__init__()\n",
        "\n",
        "        self.down_sample = down_sample\n",
        "        self.expand = in_c != out_c\n",
        "\n",
        "        stride = 2 if down_sample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, intra_c, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(intra_c, intra_c, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(intra_c)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(intra_c, out_c, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        if down_sample or self.expand:\n",
        "            self.convert_id = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_c)\n",
        "            )\n",
        "        else:\n",
        "            self.convert_id = nn.Sequential() # Identity function\n",
        "\n",
        "        # 마지막 BatchNorm의 gamma 값을 0으로 설정\n",
        "        self.bn3.weight.data.fill_(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        if self.down_sample or self.expand:\n",
        "            identity = self.convert_id(x)\n",
        "\n",
        "        out = F.relu(out + identity)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.init_block = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.ResBlock1 = self._make_layers(64, 64, 256, cfg[0], down_sample=False)\n",
        "        self.ResBlock2 = self._make_layers(256, 128, 512, cfg[1], down_sample=True)\n",
        "        self.ResBlock3 = self._make_layers(512, 256, 1024, cfg[2], down_sample=True)\n",
        "        self.ResBlock4 = self._make_layers(1024, 512, 2048, cfg[3], down_sample=True)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(2048, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.init_block(x)\n",
        "        out = self.ResBlock1(out)\n",
        "        out = self.ResBlock2(out)\n",
        "        out = self.ResBlock3(out)\n",
        "        out = self.ResBlock4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out= out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, in_c, intra_c, out_c, num_block, down_sample):\n",
        "        layers = []\n",
        "        layers.append(ResNet_block(in_c = in_c, intra_c = intra_c, out_c = out_c, down_sample = down_sample))\n",
        "        for _ in range(num_block - 1):\n",
        "            layers.append(ResNet_block(in_c = out_c, intra_c = intra_c, out_c = out_c, down_sample = False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "print('STEP 4: INSTANTIATE MODEL CLASS (BatchNorm=0)')\n",
        "\n",
        "model = ResNet()\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRX3VstFrani",
        "outputId": "cc05d85b-7264-4acc-9fab-bdb47a1d91c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 3: CREATE MODEL CLASS (BatchNorm=0)\n",
            "STEP 4: INSTANTIATE MODEL CLASS (BatchNorm=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('STEP 5: INSTANTIATE LOSS CLASS(BatchNorm=0)')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "print('STEP 6: INSTANTIATE OPTIMIZER CLASS(BatchNorm=0)')\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "print('STEP 7: TRAIN THE MODEL(BatchNorm=0)')\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epochs: {epoch}. Loss: {epoch_loss}. Accuracy: {epoch_accuracy}. Elapsed time: {elapsed_time} sec\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLu1YoPZrrGu",
        "outputId": "75b13970-ce01-4fef-e4e2-5837fd603173"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 5: INSTANTIATE LOSS CLASS(BatchNorm=0)\n",
            "STEP 6: INSTANTIATE OPTIMIZER CLASS(BatchNorm=0)\n",
            "STEP 7: TRAIN THE MODEL(BatchNorm=0)\n",
            "Epochs: 0. Loss: 0.8040339613364915. Accuracy: 65.10666666666667. Elapsed time: 48.39483022689819 sec\n",
            "Epochs: 1. Loss: 0.6907963772951546. Accuracy: 70.44666666666667. Elapsed time: 46.08161234855652 sec\n",
            "Epochs: 2. Loss: 0.6451078468965272. Accuracy: 73.2. Elapsed time: 47.136478662490845 sec\n",
            "Epochs: 3. Loss: 0.5712549579093011. Accuracy: 76.54666666666667. Elapsed time: 46.45555305480957 sec\n",
            "Epochs: 4. Loss: 0.5339952298140122. Accuracy: 78.62. Elapsed time: 46.73963928222656 sec\n",
            "Epochs: 5. Loss: 0.5007062867536383. Accuracy: 80.02. Elapsed time: 46.75094485282898 sec\n",
            "Epochs: 6. Loss: 0.4257145872560598. Accuracy: 82.74666666666667. Elapsed time: 46.622796297073364 sec\n",
            "Epochs: 7. Loss: 0.3973720400767811. Accuracy: 84.14666666666666. Elapsed time: 46.5822217464447 sec\n",
            "Epochs: 8. Loss: 0.3326757485836239. Accuracy: 86.89333333333333. Elapsed time: 46.47489905357361 sec\n",
            "Epochs: 9. Loss: 0.30280843743328323. Accuracy: 88.01333333333334. Elapsed time: 46.428720235824585 sec\n",
            "Epochs: 10. Loss: 0.24479714092814317. Accuracy: 90.64. Elapsed time: 46.39094018936157 sec\n",
            "Epochs: 11. Loss: 0.19929765682604353. Accuracy: 92.36666666666666. Elapsed time: 46.381468296051025 sec\n",
            "Epochs: 12. Loss: 0.19532898800857998. Accuracy: 92.44666666666667. Elapsed time: 46.34567856788635 sec\n",
            "Epochs: 13. Loss: 0.14895586205362263. Accuracy: 94.36. Elapsed time: 46.3864164352417 sec\n",
            "Epochs: 14. Loss: 0.12289587531428216. Accuracy: 95.28666666666666. Elapsed time: 46.39362168312073 sec\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}